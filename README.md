# ğŸ§  Transformers from Scratch

This repository contains an implementation of attention mechanisms and transformer architectures built entirely from scratch using PyTorch. The goal is to demystify the inner workings of transformers by building them piece by piece, without relying on high-level abstractions.

---

## ğŸš€ Whatâ€™s Included

- Scaled Dot-Product Attention
- Multi-Head Attention
- Positional Encoding
- Transformer Encoder Block
- Transformer Decoder Block (optional)
- Vision Transformer (ViT) [coming soon]
- Self-contained training scripts
- Example usage on toy datasets (e.g., classification)

---

## ğŸ› ï¸ Technologies

- Python 3.x
- PyTorch
- Jupyter Notebooks / .py scripts

---

## ğŸ“– Sources & References

These resources inspired and guided this project:

- [The Annotated Transformer (Harvard NLP)](http://nlp.seas.harvard.edu/2018/04/03/attention.html)
- [Attention Is All You Need (Vaswani et al., 2017)](https://arxiv.org/abs/1706.03762)
- [The Illustrated Transformer by Jay Alammar](https://jalammar.github.io/illustrated-transformer/)
- [PyTorch Documentation](https://pytorch.org/docs/stable/index.html)

---

## ğŸ§ª Usage

Clone the repository:

```bash
git clone https://github.com/your-username/transformers-from-scratch.git
cd transformers-from-scratch
